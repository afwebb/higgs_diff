{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib64/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inDF = pd.read_csv('../inputData/87_4j.csv')\n",
    "#inDF.loc[ inDF['higgs_pt'] <= 250000, 'higgs_pt'] = 0\n",
    "#inDF.loc[ inDF['higgs_pt'] > 250000, 'higgs_pt'] = 1\n",
    "pd_train, pd_test = train_test_split(inDF, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd_test['higgs_pt']\n",
    "y_train = pd_train['higgs_pt']\n",
    "pd_train = pd_train.drop(['higgs_pt'],axis=1)                                                                                                         \n",
    "pd_test = pd_test.drop(['higgs_pt'],axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert data to tensors\n",
    "x_train = torch.tensor(pd_train.values, dtype=torch.float32)\n",
    "x_test = torch.tensor(pd_test.values, dtype=torch.float32)\n",
    "y_train = torch.FloatTensor(y_train.values)\n",
    "y_test = torch.FloatTensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_train\n",
    "Y = y_train\n",
    "\n",
    "X_test = x_test\n",
    "Y_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    x_normed = x / x.max(0, keepdim=True)[0]\n",
    "    return x_normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalize(X)\n",
    "Y = normalize(Y)\n",
    "\n",
    "X_test = normalize(X_test)\n",
    "Y_test = normalize(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OldNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(50, 50)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dout = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(50, 100)\n",
    "        self.prelu = nn.PReLU(1)\n",
    "        self.out = nn.Linear(100, 1)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        a1 = self.fc1(input_)\n",
    "        h1 = self.relu1(a1)\n",
    "        dout = self.dout(h1)\n",
    "        a2 = self.fc2(dout)\n",
    "        h2 = self.prelu(a2)\n",
    "        a3 = self.out(h2)\n",
    "        y = self.out_act(a3)\n",
    "        return y\n",
    "    \n",
    "oldNet = OldNet()\n",
    "#opt = optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, D_in, nodes, layers):\n",
    "        self.layers = layers\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(D_in, nodes)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dout = nn.Dropout(0.2)\n",
    "        #self.fc2 = nn.Linear(50, 100)\n",
    "        self.fc = nn.Linear(nodes, nodes)\n",
    "        self.prelu = nn.PReLU(1)\n",
    "        self.out = nn.Linear(nodes, 1)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        h1 = self.dout(self.relu1(self.fc1(input_)))\n",
    "        for i in range(self.layers):\n",
    "            h1 = self.dout(self.relu1(self.fc(h1)))\n",
    "        a1 = self.out(h1)\n",
    "        y = self.out_act(a1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_epoch(model, opt, criterion, batch_size=10000):\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    opt.zero_grad()\n",
    "    # (1) Forward\n",
    "    y_hat = net(X)\n",
    "    # (2) Compute diff\n",
    "    loss = criterion(y_hat[:,0], Y)\n",
    "    # (3) Compute gradients\n",
    "    loss.backward()\n",
    "    # (4) update weights\n",
    "    opt.step()        \n",
    "    losses.append(loss.data.numpy())\n",
    "    \n",
    "    return loss, y_hat[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class param:\n",
    "    def __init__(self, epochs, layers, nodes, auc = 0, loss = 1):\n",
    "        self.epochs = epochs\n",
    "        self.layers = layers\n",
    "        self.nodes = nodes\n",
    "        self.auc = auc\n",
    "        self.train_loss = None\n",
    "        self.test_loss = None\n",
    "        self.y_pred = None\n",
    "        self.y_pred_test = None\n",
    "        self.net = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = [2500]\n",
    "nLayers = [5, 8, 12, 16]\n",
    "nNodes = [50, 100, 200, 300]\n",
    "\n",
    "param_grid = []\n",
    "for ep in num_epochs:\n",
    "    for la in nLayers:\n",
    "        for node in nNodes:\n",
    "            param_grid.append(param(ep, la, node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_scaled = (y_predicted-y_predicted.min())/(y_predicted.max()-y_predicted.min())\n",
    "y_pred_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch]: 0, [Train Loss]: 0.4012, [Test Loss]: 0.3757\n",
      "[Epoch]: 100, [Train Loss]: 0.0661, [Test Loss]: 0.0887\n",
      "[Epoch]: 200, [Train Loss]: 0.0500, [Test Loss]: 0.0663\n",
      "[Epoch]: 300, [Train Loss]: 0.0491, [Test Loss]: 0.0654\n",
      "[Epoch]: 400, [Train Loss]: 0.0480, [Test Loss]: 0.0641\n",
      "[Epoch]: 500, [Train Loss]: 0.0465, [Test Loss]: 0.0620\n",
      "[Epoch]: 600, [Train Loss]: 0.0453, [Test Loss]: 0.0600\n",
      "[Epoch]: 700, [Train Loss]: 0.0443, [Test Loss]: 0.0583\n",
      "[Epoch]: 800, [Train Loss]: 0.0431, [Test Loss]: 0.0562\n",
      "[Epoch]: 900, [Train Loss]: 0.0423, [Test Loss]: 0.0548\n",
      "[Epoch]: 1000, [Train Loss]: 0.0418, [Test Loss]: 0.0542\n",
      "[Epoch]: 1100, [Train Loss]: 0.0415, [Test Loss]: 0.0535\n",
      "[Epoch]: 1200, [Train Loss]: 0.0410, [Test Loss]: 0.0532\n",
      "[Epoch]: 1300, [Train Loss]: 0.0406, [Test Loss]: 0.0528\n",
      "[Epoch]: 1400, [Train Loss]: 0.0405, [Test Loss]: 0.0524\n",
      "[Epoch]: 1500, [Train Loss]: 0.0403, [Test Loss]: 0.0522\n",
      "[Epoch]: 1600, [Train Loss]: 0.0400, [Test Loss]: 0.0520\n",
      "[Epoch]: 1700, [Train Loss]: 0.0400, [Test Loss]: 0.0520\n",
      "[Epoch]: 1900, [Train Loss]: 0.0396, [Test Loss]: 0.0517\n",
      "[Epoch]: 2000, [Train Loss]: 0.0395, [Test Loss]: 0.0515\n",
      "[Epoch]: 2100, [Train Loss]: 0.0394, [Test Loss]: 0.0514\n",
      "[Epoch]: 2200, [Train Loss]: 0.0393, [Test Loss]: 0.0514\n",
      "Nodes: 200\n",
      "Layers: 8\n",
      "Train Loss: 0.039252065\n",
      "Test Loss: 0.051401448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "last_p = [param_grid[6]]\n",
    "#for p in param_grid:\n",
    "for p in last_p:\n",
    "    net = Net(pd_train.shape[1], p.nodes, p.layers)\n",
    "    opt = optim.Adam(net.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
    "    criterion = nn.L1Loss()\n",
    "    y_pred = []\n",
    "    y_test_pred=[]\n",
    "    e_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    for e in range(p.epochs):\n",
    "        e_loss, y_pred = train_epoch(net, opt, criterion) \n",
    "        #e_losses.append(loss)\n",
    "        if e%100==0:\n",
    "            y_pred_test = net(X_test)[:,0]\n",
    "            test_loss = criterion(y_pred_test, Y_test).float().detach().numpy()\n",
    "            test_losses.append(test_loss)\n",
    "            print(\"[Epoch]: %i, [Train Loss]: %.4f, [Test Loss]: %.4f\" % (e, e_loss, test_loss))\n",
    "            if e>300 and test_losses[-2]-test_losses[-1]<10e-8: \n",
    "                p.epochs=e\n",
    "                break\n",
    "    \n",
    "    p.net = net\n",
    "    p.train_loss = e_loss.float().detach().numpy()\n",
    "    p.test_loss = test_loss\n",
    "    p.y_pred_test = y_pred_test.float().detach().numpy()\n",
    "    p.y_pred = y_pred.float().detach().numpy()\n",
    "    #p.auc = sk.metrics.roc_auc_score(y_train,y_predicted)\n",
    "    \n",
    "    print(\"Nodes: \"+str(p.nodes))\n",
    "    print(\"Layers: \"+str(p.layers))\n",
    "    print(\"Train Loss: \"+str(p.train_loss))\n",
    "    print(\"Test Loss: \"+str(p.test_loss))\n",
    "    print(\"\")\n",
    "    \n",
    "    del net, opt, criterion, y_pred, y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid[2].y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_predicted = param_grid[6].y_pred\n",
    "y_pred_scaled = (y_predicted-y_predicted.min())/(y_predicted.max()-y_predicted.min())\n",
    "plt.hist(Y, 20, log=True, range=(0, 0.8), alpha=0.5, label='truth')\n",
    "plt.hist(y_pred_scaled, 20, log=True, range=(0, 0.8), alpha=0.5, label='train')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(Y_test, 20, log=True, range=(0, 0.8), alpha=0.5, label='truth')\n",
    "plt.hist(param_grid[6].y_pred_test,20, log=True, range=(0, 0.8), alpha=0.5, label='test')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_predicted = y_pred.float().detach().numpy()\n",
    "cutoff = [0.2, 0.25, 0.3]\n",
    "\n",
    "plt.figure()\n",
    "for c in cutoff:\n",
    "    yTrain = np.where(Y > c, 1, 0)\n",
    "    ypTrain = param_grid[2].y_pred\n",
    "\n",
    "    auc = sk.metrics.roc_auc_score(yTrain,ypTrain)\n",
    "    fpr, tpr = sk.metrics.roc_curve(yTrain,ypTrain)\n",
    "\n",
    "    plt.plot(fpr, tpr, label='AUC = %.3f, cutoff = %0.2f' %(auc, c))\n",
    "\n",
    "plt.title(\"pyTorch Train ROC, layers=%i, nodes=%i\" %(param_grid[2].layers, param_grid[2].nodes))\n",
    "plt.legend(loc='lower right')    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_predicted = y_pred.float().detach().numpy()\n",
    "cutoff = [0.1, 0.15, 0.2, 0.3, 0.4]\n",
    "\n",
    "plt.figure()\n",
    "for c in cutoff:\n",
    "    yTest = np.where(Y_test > c, 1, 0)\n",
    "    ypTest = param_grid[2].y_pred_test\n",
    "\n",
    "    auc = sk.metrics.roc_auc_score(yTest,ypTest)\n",
    "    roc_array = sk.metrics.roc_curve(yTest,ypTest)\n",
    "\n",
    "    plt.plot(roc_array[1], label='AUC = %.3f, cutoff = %0.2f' %(auc, c))\n",
    "\n",
    "plt.title(\"pyTorch Test ROC, layers=%i, nodes=%i\" %(param_grid[2].layers, param_grid[2].nodes))\n",
    "plt.legend(loc='lower right')    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = Variable(x_test, volatile=True), Variable(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_test = y_pred_test.detach().numpy()\n",
    "auc = sk.metrics.roc_auc_score(y_test,y_pred_test)\n",
    "\n",
    "roc_array = sk.metrics.roc_curve(y_test,y_pred_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(roc_array[1], label='AUC = '+str(auc))\n",
    "plt.title(\"pytorch test ROC\")\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
